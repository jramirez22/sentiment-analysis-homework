{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the corpora/stopwords\n",
    "import nltk\n",
    "\n",
    "# Uncomment the line below to open the download window\n",
    "# we use the download window to download the stopwords\n",
    "# nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "from typing import Generator, List\n",
    "\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim.utils import simple_preprocess\n",
    "from nltk.corpus import stopwords\n",
    "from spacy.lang.en import English"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✔ Download and installation successful\n",
      "You can now load the package via spacy.load('en_core_web_md')\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.cli import download\n",
    "\n",
    "# Uncomment the line below to download en_core_web_*\n",
    "# Download only one\n",
    "\n",
    "# download(\"en_core_web_trf\")\n",
    "download(\"en_core_web_md\")\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(r\"data/interim/model_3/review_classes.pkl\", \"rb\") as input_file:\n",
    "    review_classes = pickle.load(input_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We went to the hotel directly to book a room. The receptionist at first gave us a really high price then lowered it. When we asked how much it costs in qetales she gave us an 8.2 comission rate to dollars and I knew she was randomly goving us a non existing rate so then she \"lowered\" it to the real rate. After we agreed that the price includes breakfast the following morning we get to breakfast and received two plain pieces of toast and fruit while theother tables received also eggs and plantines. So I asked if we also get eggs abd plantines and she replied \"no\". How come we didn\\'t get the same breakfast when we paid for it?? Not a good experience at all at the hotel. There are much better places in Antigua to stay.'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See the first negative review to check if the dictionary was loaded correctly\n",
    "review_classes[\"NEG\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "positive_reviews = review_classes[\"POS\"]\n",
    "negative_reviews = review_classes[\"NEG\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def sentences_to_words(sentences: List[str]) -> List[List[str]]:\n",
    "    words = []\n",
    "    for sentence in sentences:\n",
    "        # https://radimrehurek.com/gensim/utils.html#gensim.utils.simple_preprocess\n",
    "        words.append(simple_preprocess(str(sentence), deacc=True))  # deacc=True elimina la puntuación\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'went', 'to', 'the', 'hotel', 'directly', 'to', 'book', 'room', 'the']\n"
     ]
    }
   ],
   "source": [
    "negative_words = sentences_to_words(negative_reviews)\n",
    "positive_words = sentences_to_words(positive_reviews)\n",
    "\n",
    "# Check the first 10 words of the first negative review\n",
    "index = 0\n",
    "if len(negative_words[index]) > 10:\n",
    "    print(negative_words[index][0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def remove_stopwords(documents: List[List[str]]) -> List[List[str]]:\n",
    "    return [[word for word in simple_preprocess(str(doc)) if word not in stopwords.words('english')]\n",
    "            for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for the first negative review\n",
      "- Number of words with stopwords:  132\n",
      "- Number of words without stopwords:  71\n"
     ]
    }
   ],
   "source": [
    "positive_words_wo_stopwords = remove_stopwords(positive_words)\n",
    "negative_words_wo_stopwords = remove_stopwords(negative_words)\n",
    "\n",
    "# Statistics for the first negative review . . .\n",
    "print(\"Statistics for the first negative review\")\n",
    "print(\"- Number of words with stopwords: \", len(negative_words[0]))\n",
    "print(\"- Number of words without stopwords: \", len(negative_words_wo_stopwords[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def learn_bigrams(documents: List[List[str]]) -> List[List[str]]:\n",
    "    # We learn bigrams\n",
    "    # https://radimrehurek.com/gensim/models/phrases.html#gensim.models.phrases.Phrases\n",
    "    bigram = Phrases(documents, min_count=5, threshold=10)\n",
    "\n",
    "    # we reduce the bigram model to its minimal functionality\n",
    "    bigram_mod = Phraser(bigram)\n",
    "\n",
    "    # we apply the bigram model to our documents\n",
    "    return bigram_mod\n",
    "\n",
    "\n",
    "def create_bigrams(bigram_model, documents: List[List[str]]):\n",
    "    return [bigram_model[doc] for doc in documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bigram_model = learn_bigrams(negative_words_wo_stopwords + positive_words_wo_stopwords)\n",
    "negative_words_wo_stopwords_bigrams = create_bigrams(bigram_model, negative_words_wo_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for the first negative review\n",
      "- Number of words with stopwords:  132\n",
      "- Number of words without stopwords and with bigrams:  68\n"
     ]
    }
   ],
   "source": [
    "# Statistics for the first negative review . . .\n",
    "print(\"Statistics for the first negative review\")\n",
    "print(\"- Number of words with stopwords: \", len(negative_words[0]))\n",
    "print(\"- Number of words without stopwords and with bigrams: \", len(negative_words_wo_stopwords_bigrams[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatization(nlp: English, texts: List[List[str]], allowed_postags: List = None) -> List[List[str]]:\n",
    "    if allowed_postags is None:\n",
    "        allowed_postags = ['NOUN', 'ADJ', 'VERB', 'ADV']\n",
    "\n",
    "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
    "    texts_out = []\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent))\n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    return texts_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "negative_words_wo_stopwords_bigrams_pos = lemmatization(nlp, negative_words_wo_stopwords_bigrams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics for the first negative review\n",
      "- Number of words without stopwords and with bigrams:  68\n",
      "- Number of words without stopwords, with bigrams and lemmnatization:  61\n"
     ]
    }
   ],
   "source": [
    "# Statistics for the first negative review . . .\n",
    "print(\"Statistics for the first negative review\")\n",
    "print(\"- Number of words without stopwords and with bigrams: \", len(negative_words_wo_stopwords_bigrams[0]))\n",
    "print(\"- Number of words without stopwords, with bigrams and lemmnatization: \", len(negative_words_wo_stopwords_bigrams_pos[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(documents: List[str], bigram_model) -> List[List[str]]:\n",
    "\n",
    "    document_words = sentences_to_words(documents)\n",
    "    document_words = remove_stopwords(document_words)\n",
    "    document_words = create_bigrams(bigram_model, document_words)\n",
    "    document_words = lemmatization(nlp, document_words)\n",
    "\n",
    "    return document_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_words = tokenize(positive_reviews, bigram_model)\n",
    "negative_words = tokenize(negative_reviews, bigram_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['we', 'went', 'to', 'the', 'hotel', 'directly', 'to', 'book', 'room', 'the', 'receptionist', 'at', 'first', 'gave', 'us', 'really', 'high', 'price', 'then', 'lowered', 'it', 'when', 'we', 'asked', 'how', 'much', 'it', 'costs', 'in', 'qetales', 'she', 'gave', 'us', 'an', 'comission', 'rate', 'to', 'dollars', 'and', 'knew', 'she', 'was', 'randomly', 'goving', 'us', 'non', 'existing', 'rate', 'so', 'then', 'she', 'lowered', 'it', 'to', 'the', 'real', 'rate', 'after', 'we', 'agreed', 'that', 'the', 'price', 'includes', 'breakfast', 'the', 'following', 'morning', 'we', 'get', 'to', 'breakfast', 'and', 'received', 'two', 'plain', 'pieces', 'of', 'toast', 'and', 'fruit', 'while', 'theother', 'tables', 'received', 'also', 'eggs', 'and', 'plantines', 'so', 'asked', 'if', 'we', 'also', 'get', 'eggs', 'abd', 'plantines', 'and', 'she', 'replied', 'no', 'how', 'come', 'we', 'didn', 'get', 'the', 'same', 'breakfast', 'when', 'we', 'paid', 'for', 'it', 'not', 'good', 'experience', 'at', 'all', 'at', 'the', 'hotel', 'there', 'are', 'much', 'better', 'places', 'in', 'antigua', 'to', 'stay']\n",
      "['go', 'hotel', 'directly', 'book', 'room', 'receptionist', 'first', 'really', 'high', 'price', 'lower', 'ask', 'much', 'cost', 'qetale', 'gave_us', 'comission', 'rate', 'dollar', 'know', 'randomly', 'gove', 'exist', 'rate', 'lower', 'real', 'rate', 'agree', 'price', 'include', 'breakfast', 'follow', 'morning', 'get', 'breakfast', 'receive', 'plain', 'piece', 'toast', 'fruit', 'theoth', 'table', 'receive', 'also', 'egg', 'plantine', 'ask', 'also', 'get', 'egg', 'plantine', 'reply', 'come', 'get', 'breakfast', 'pay', 'good', 'experience', 'hotel', 'place', 'stay']\n"
     ]
    }
   ],
   "source": [
    "print(sentences_to_words(negative_reviews)[0])\n",
    "print(negative_words[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"data/interim/model_3/positive_words.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(positive_words, output_file)\n",
    "\n",
    "with open(r\"data/interim/model_3/negative_words.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(negative_words, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(r\"data/interim/model_3/bigram_model.pkl\", \"wb\") as output_file:\n",
    "    pickle.dump(bigram_model, output_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
